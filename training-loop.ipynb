{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPRTisE7an/M4yNX2fIbe/1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.nn.parallel import DistributedDataParallel\n","from torch.cuda.amp import GradScaler, autocast"],"metadata":{"id":"3Yzi7oKHqe3e","executionInfo":{"status":"ok","timestamp":1701271232096,"user_tz":-330,"elapsed":6685,"user":{"displayName":"Saumya Chaudhary 4-Year B.Tech. Electronics Engineering","userId":"11792631033894863156"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the model, optimizer, and criterion\n","model = GPT2WithRotary(vocab_size).to(device)\n","optimizer = optim.AdamW(model.parameters(), lr=2e-4)\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"j0o3yP8PqxPP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_step(data, model, criterion, optimizer, scaler=None):\n","    inputs, targets = data\n","    inputs, targets = inputs.to(device), targets.to(device)\n","\n","    optimizer.zero_grad()\n","\n","    with autocast():\n","        outputs = model(inputs)\n","        loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n","\n","    if scaler is not None:\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","    else:\n","        loss.backward()\n","        optimizer.step()\n","\n","    return loss.item()\n"],"metadata":{"id":"RVrqOuK0q7mg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0.0\n","\n","    for batch_data in train_dataloader:\n","        loss = train_step(batch_data, model, criterion, optimizer, scaler)\n","        total_loss += loss\n","\n","    average_loss = total_loss / len(train_dataloader)\n","    print(f\"Epoch {epoch + 1}, Loss: {average_loss}\")\n","\n","# Save the model after training\n","\n"],"metadata":{"id":"Mpa95u8QrBKN"},"execution_count":null,"outputs":[]}]}